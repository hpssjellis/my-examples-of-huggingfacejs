<!-- polyfill for firefox + import maps   <script src="https://unpkg.com/es-module-shims@1.7.0/dist/es-module-shims.js"></script> -->
<script type="importmap">
   {"imports": {"@huggingface/inference": "https://cdn.jsdelivr.net/npm/@huggingface/inference@1.7.1/+esm"}}
</script>


<h6> version 0.2.2-12</h6>
Running model: <span id="myModel">...</span> <br>
Prompt: <input type="text" value="What is a large language model" id="myPrompt"> <br>
Token ID(optional): <input type="password" value="" id="myTokenID"> <br>

Output: <span id="myOutput">...</span> <br>

<input type="button" value="Huggingface Chat" onclick="{  
   launch()
}"> <br>


<script type="module">
import { HfInference } from "@huggingface/inference";
let running = false;
async function launch() {
	if (running) {
		return;
	}
	running = true;
	try {
		const hf = new HfInference(
			document.getElementById("myTokenID").value.trim() || undefined
		);
		const model = "google/flan-t5-xxl";  //document.getElementById("model").value.trim();  // set this
		document.getElementById("myModel").innerHTML = `<b>${model}</b>`;
		
		const prompt = document.getElementById("myPrompt").value.trim();
		document.getElementById("myOutput").innerHTML = "";
		for await (const output of hf.textGenerationStream({
			model,
			inputs: prompt,
			parameters: { max_new_tokens: 250 }
		}, {
			use_cache: false
		})) {
			document.getElementById("myOutput").innerHTML += output.token.text;
		}
	} catch (err) {
		alert("Error: " + err.message);
	} finally {
		running = false;
	}
}
window.launch = launch;
</script>
